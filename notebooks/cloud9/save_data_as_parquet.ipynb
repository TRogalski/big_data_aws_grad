{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d05771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec9d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"spark-xml_2.12-0.15.0.jar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8964410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/ubuntu/miniconda3/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ubuntu/miniconda3/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntu/.ivy2/jars\n",
      "org.apache.spark#spark-hadoop-cloud_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ad4d6087-5960-4aba-96b5-4fc5d382a27e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-hadoop-cloud_2.12;3.2.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.1 in central\n",
      "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound org.apache.hadoop#hadoop-openstack;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-annotations;3.3.1 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.14 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.12.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.12.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.12.3 in central\n",
      "\tfound joda-time#joda-time;2.10.10 in central\n",
      "\tfound com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.12.3 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound org.apache.hadoop#hadoop-azure;3.3.1 in central\n",
      "\tfound com.microsoft.azure#azure-storage;7.0.1 in central\n",
      "\tfound com.microsoft.azure#azure-keyvault-core;1.0.0 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.apache.hadoop#hadoop-cloud-storage;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-aliyun;3.3.1 in central\n",
      "\tfound com.aliyun.oss#aliyun-sdk-oss;3.4.1 in central\n",
      "\tfound org.jdom#jdom;1.1 in central\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
      "\tfound stax#stax-api;1.0.1 in central\n",
      "\tfound com.aliyun#aliyun-java-sdk-core;3.4.0 in central\n",
      "\tfound com.aliyun#aliyun-java-sdk-ram;3.0.0 in central\n",
      "\tfound com.aliyun#aliyun-java-sdk-sts;3.0.0 in central\n",
      "\tfound com.aliyun#aliyun-java-sdk-ecs;4.2.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-azure-datalake;3.3.1 in central\n",
      "\tfound com.microsoft.azure#azure-data-lake-store-sdk;2.3.9 in central\n",
      "\tfound org.apache.hadoop#hadoop-cos;3.3.1 in central\n",
      "\tfound com.qcloud#cos_api-bundle;5.6.19 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.43.v20210629 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      ":: resolution report :: resolve 2265ms :: artifacts dl 85ms\n",
      "\t:: modules in use:\n",
      "\tcom.aliyun#aliyun-java-sdk-core;3.4.0 from central in [default]\n",
      "\tcom.aliyun#aliyun-java-sdk-ecs;4.2.0 from central in [default]\n",
      "\tcom.aliyun#aliyun-java-sdk-ram;3.0.0 from central in [default]\n",
      "\tcom.aliyun#aliyun-java-sdk-sts;3.0.0 from central in [default]\n",
      "\tcom.aliyun.oss#aliyun-sdk-oss;3.4.1 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.12.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.12.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.12.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.12.3 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcom.microsoft.azure#azure-data-lake-store-sdk;2.3.9 from central in [default]\n",
      "\tcom.microsoft.azure#azure-keyvault-core;1.0.0 from central in [default]\n",
      "\tcom.microsoft.azure#azure-storage;7.0.1 from central in [default]\n",
      "\tcom.qcloud#cos_api-bundle;5.6.19 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tjoda-time#joda-time;2.10.10 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aliyun;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-azure-datalake;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-cloud-storage;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-cos;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-openstack;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.14 from central in [default]\n",
      "\torg.apache.spark#spark-hadoop-cloud_2.12;3.2.1 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.43.v20210629 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 from central in [default]\n",
      "\torg.jdom#jdom;1.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\tstax#stax-api;1.0.1 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 by [org.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   43  |   0   |   0   |   1   ||   42  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ad4d6087-5960-4aba-96b5-4fc5d382a27e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 42 already retrieved (0kB/93ms)\n",
      "23/01/07 16:57:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"spark-xml\")\\\n",
    ".config(\"spark.jars.packages\", \"org.apache.spark:spark-hadoop-cloud_2.12:3.2.1\")\\\n",
    ".config(\"spark.jars\", PATH)\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5609cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"ASIA5CTRO67EF5LRWV4Y\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"THzYAZn3b6h652XuTH3L36g0/RXF79C5wosC7aT7\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.s3a.session.token\", \"FwoGZXIvYXdzEAIaDABxRvVBENur0HdlaCLCAaT4INNN4nbR7QhfPrFY8rtGzxbyrXcyJNAUVPDS5IQgJABDnwT3ENO7/WmgH2rancR0bi8GQN+6t+h0B48sg5O5WC5iFC+XmecStfVeABuwPLPu3JX/N80/tYJle4Z61xbA8vkTTGKArt1gZiYkKYIoesPt/d1oblShhiXAaZWjMvinZle9n+9Mfod59QzkOjEs/4U3GuKGuax1UtKr/dWAx7HW69hWgyCvYNHLbNBKGfJqFpr1CPqWfCPAnP7V2QUCKOPB5p0GMi1w1V222QbAPXFyyQ+J+yus302ABGhjiihx5wAudKHRM4fU1VjiwsA+tQ8BF3A=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e84db80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('xml')\\\n",
    "               .options(rowTag='row', rootTag='tags')\\\n",
    "               .load('s3a://english-stackexchange-com/raw/2023-01-10/Tags.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33912193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---+--------------+-----------+\n",
      "|_Count|_ExcerptPostId|_Id|      _TagName|_WikiPostId|\n",
      "+------+--------------+---+--------------+-----------+\n",
      "|  5772|          2880|  2|     etymology|       2879|\n",
      "| 13661|         14043|  7|       grammar|      14042|\n",
      "|    24|          null| 10|    short-form|       null|\n",
      "|   961|         21906| 11|capitalization|      21905|\n",
      "|   103|         43838| 16|        sports|      43837|\n",
      "|  2898|         18038| 21|   punctuation|      18037|\n",
      "|   407|         25766| 22|        quotes|      25765|\n",
      "|   502|         61142| 27|        speech|      61141|\n",
      "|   459|         36563| 28|    politeness|      36562|\n",
      "|    50|          null| 30|    verb-forms|       null|\n",
      "|  1061|         36550| 32|  conjunctions|      36549|\n",
      "|   859|          6739| 35|   possessives|       6738|\n",
      "|   576|         43138| 36|    apostrophe|      43137|\n",
      "|    32|         44820| 38|           esl|      44819|\n",
      "|     7|          null| 39|  teaching-aid|       null|\n",
      "|  3867|         18217| 40|   differences|      18216|\n",
      "|   118|         51720| 41|   confusables|      51719|\n",
      "|  2615|          3298| 50| pronunciation|       3297|\n",
      "| 16544|          3294| 54|       meaning|       3293|\n",
      "|   549|         12049| 59|       writing|      12048|\n",
      "+------+--------------+---+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "391e20d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _Count: long (nullable = true)\n",
      " |-- _ExcerptPostId: long (nullable = true)\n",
      " |-- _Id: long (nullable = true)\n",
      " |-- _TagName: string (nullable = true)\n",
      " |-- _WikiPostId: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f196143",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c78e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"_Count\", col(\"_Count\").cast(IntegerType()))\\\n",
    "       .withColumn(\"_ExcerptPostId\", col(\"_ExcerptPostId\").cast(StringType()))\\\n",
    "       .withColumn(\"_Id\", col(\"_Id\").cast(StringType()))\\\n",
    "       .withColumn(\"_TagName\", col(\"_TagName\").cast(StringType()))\\\n",
    "       .withColumn(\"_WikiPostId\", col(\"_WikiPostId\").cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc1d3885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _Count: integer (nullable = true)\n",
      " |-- _ExcerptPostId: string (nullable = true)\n",
      " |-- _Id: string (nullable = true)\n",
      " |-- _TagName: string (nullable = true)\n",
      " |-- _WikiPostId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae4fb968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.option(\"schema\", write_schema)\\\n",
    "        .parquet(\"s3a://english-stackexchange-com/parquet/Tags.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e467154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = spark.read.parquet(\"s3a://english-stackexchange-com/parquet/Tags.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26aba768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---+--------------+-----------+\n",
      "|_Count|_ExcerptPostId|_Id|      _TagName|_WikiPostId|\n",
      "+------+--------------+---+--------------+-----------+\n",
      "|  5772|          2880|  2|     etymology|       2879|\n",
      "| 13661|         14043|  7|       grammar|      14042|\n",
      "|    24|          null| 10|    short-form|       null|\n",
      "|   961|         21906| 11|capitalization|      21905|\n",
      "|   103|         43838| 16|        sports|      43837|\n",
      "|  2898|         18038| 21|   punctuation|      18037|\n",
      "|   407|         25766| 22|        quotes|      25765|\n",
      "|   502|         61142| 27|        speech|      61141|\n",
      "|   459|         36563| 28|    politeness|      36562|\n",
      "|    50|          null| 30|    verb-forms|       null|\n",
      "|  1061|         36550| 32|  conjunctions|      36549|\n",
      "|   859|          6739| 35|   possessives|       6738|\n",
      "|   576|         43138| 36|    apostrophe|      43137|\n",
      "|    32|         44820| 38|           esl|      44819|\n",
      "|     7|          null| 39|  teaching-aid|       null|\n",
      "|  3867|         18217| 40|   differences|      18216|\n",
      "|   118|         51720| 41|   confusables|      51719|\n",
      "|  2615|          3298| 50| pronunciation|       3297|\n",
      "| 16544|          3294| 54|       meaning|       3293|\n",
      "|   549|         12049| 59|       writing|      12048|\n",
      "+------+--------------+---+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d10ce2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _Count: integer (nullable = true)\n",
      " |-- _ExcerptPostId: string (nullable = true)\n",
      " |-- _Id: string (nullable = true)\n",
      " |-- _TagName: string (nullable = true)\n",
      " |-- _WikiPostId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08b75350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-------------+------------------+\n",
      "|summary|            _Count|    _ExcerptPostId|               _Id|     _TagName|       _WikiPostId|\n",
      "+-------+------------------+------------------+------------------+-------------+------------------+\n",
      "|  count|               986|               533|               986|          986|               533|\n",
      "|   mean|270.21703853955376|206437.31519699813|1279.6156186612577|         null|206436.31519699813|\n",
      "| stddev|1192.4703980847394|175149.57340418326| 761.6284512715282|         null|175149.57340418326|\n",
      "|    min|                 1|            101108|                10|abbreviations|            101107|\n",
      "|    max|             19971|             97375|               996|       zeugma|             97374|\n",
      "+-------+------------------+------------------+------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cc8cd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-------------+------------------+\n",
      "|summary|            _Count|    _ExcerptPostId|               _Id|     _TagName|       _WikiPostId|\n",
      "+-------+------------------+------------------+------------------+-------------+------------------+\n",
      "|  count|               986|               533|               986|          986|               533|\n",
      "|   mean|270.21703853955376|206437.31519699813|1279.6156186612577|         null|206436.31519699813|\n",
      "| stddev|1192.4703980847394|175149.57340418326| 761.6284512715282|         null|175149.57340418326|\n",
      "|    min|                 1|              2880|                 2|abbreviations|              2879|\n",
      "|    max|             19971|            597351|              2639|       zeugma|            597350|\n",
      "+-------+------------------+------------------+------------------+-------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
